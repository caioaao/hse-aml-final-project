{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Versions:\n",
      "  Python: 3.8.2 (default, Jul 16 2020, 14:00:26) \n",
      "[GCC 9.3.0]\n",
      "  pandas: 1.1.0\n",
      "  numpy: 1.19.1\n",
      "  seaborn: 0.10.1\n",
      "  sklearn: 0.23.2\n",
      "  altair: 4.1.0\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import scipy\n",
    "import altair as alt\n",
    "from altair import datum\n",
    "from tqdm.auto import tqdm, trange\n",
    "\n",
    "from src.model import tscv\n",
    "\n",
    "%run constants.py\n",
    "\n",
    "%matplotlib inline\n",
    "print(\"Versions:\")\n",
    "print(\"  Python: %s\" % sys.version)\n",
    "for module in [pd, np, sns, sklearn, alt]:\n",
    "    print(\"  %s: %s\" %(module.__name__, module.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "\n",
    "I think we have enough information to start with feature engineering now.\n",
    "\n",
    "The first step in my opinion is to define a validation pipeline, which is described in the next session.\n",
    "\n",
    "## Validation pipeline\n",
    "\n",
    "First of all, we need our metric, which sould be `sklearn.metrics.mean_squared_error(squared=False)`.\n",
    "\n",
    "Now, we need to decide how our training set should be split to validate a model. Since the problem is about forecasting, I chose to do a time-series split for this. This means I'll train on the dataset where `date_block_num < k` and predict for dataset where `date_block_num = k`, for `k in [31, 32, 33]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_block_num</th>\n",
       "      <th>item_id</th>\n",
       "      <th>shop_id</th>\n",
       "      <th>item_cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>317</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>438</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>471</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>481</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   date_block_num  item_id  shop_id  item_cnt\n",
       "0               0       33        2       1.0\n",
       "1               0      317        2       1.0\n",
       "2               0      438        2       1.0\n",
       "3               0      471        2       2.0\n",
       "4               0      481        2       1.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set = pd.read_parquet(os.path.join(PROCESSED_DATA_DIR, 'train-set-base.parquet'))\n",
    "train_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to use more of the dataset I'll use everything for CV and use the public LB score as the holdout set. This should be enough to make sure the model generalizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(array([      0,       1,       2, ..., 1506157, 1506158, 1506159]),\n",
       "  array([1506160, 1506161, 1506162, ..., 1539643, 1539644, 1539645])),\n",
       " (array([      0,       1,       2, ..., 1539643, 1539644, 1539645]),\n",
       "  array([1539646, 1539647, 1539648, ..., 1569321, 1569322, 1569323])),\n",
       " (array([      0,       1,       2, ..., 1569321, 1569322, 1569323]),\n",
       "  array([1569324, 1569325, 1569326, ..., 1600852, 1600853, 1600854]))]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tscv.split(train_set.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With that we can use scikit learn to evaluate a regressor. Let's try a random forest just as an exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:   46.6s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([45.01807499, 46.02572703, 45.87729359]),\n",
       " 'score_time': array([0.16727304, 0.03178692, 0.03285241]),\n",
       " 'test_score': array([-1.74696769, -2.22734749, -2.34067508])}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "reg = RandomForestRegressor(n_estimators=30, n_jobs=-1, verbose=1)\n",
    "cross_validate(reg, X=train_set.drop(columns='item_cnt').values, y=train_set['item_cnt'].values, \n",
    "               scoring='neg_root_mean_squared_error', verbose=1, n_jobs=-1, cv=tscv.split(train_set.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oof, it takes a while. Let's drop the number of months we are using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:   18.9s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([18.46477222, 18.5503037 , 18.15812111]),\n",
       " 'score_time': array([0.02659321, 0.02440453, 0.15769124]),\n",
       " 'test_score': array([-1.74741024, -2.2119326 , -2.35210333])}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validate(reg, X=train_set.drop(columns='item_cnt').values, y=train_set['item_cnt'].values, \n",
    "               scoring='neg_root_mean_squared_error', verbose=1, n_jobs=-1, cv=tscv.split(train_set.values, window=15))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
