{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Versions:\n",
      "  Python: 3.8.2 (default, Jul 16 2020, 14:00:26) \n",
      "[GCC 9.3.0]\n",
      "  pandas: 1.1.0\n",
      "  numpy: 1.19.1\n",
      "  seaborn: 0.10.1\n",
      "  sklearn: 0.23.2\n",
      "  altair: 4.1.0\n"
     ]
    }
   ],
   "source": [
    "            %load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import scipy\n",
    "import altair as alt\n",
    "from altair import datum\n",
    "from sklearn.model_selection import cross_validate\n",
    "from tqdm.auto import tqdm, trange\n",
    "\n",
    "from src.model import tscv\n",
    "from src.model.metrics import corrected_rmse, corrected_rmse_score\n",
    "\n",
    "%run constants.py\n",
    "\n",
    "%matplotlib inline\n",
    "print(\"Versions:\")\n",
    "print(\"  Python: %s\" % sys.version)\n",
    "for module in [pd, np, sns, sklearn, alt]:\n",
    "    print(\"  %s: %s\" %(module.__name__, module.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "\n",
    "I think we have enough information to start with feature engineering now.\n",
    "\n",
    "The first step in my opinion is to define a validation pipeline, which is described in the next session.\n",
    "\n",
    "## Validation pipeline\n",
    "\n",
    "We already have our metric, which I implemented on `src.model.metrics.corrected_rmse`.\n",
    "\n",
    "Now, we need to decide how our training set should be split to validate a model. Since the problem is about forecasting, I chose to do a time-series split for this. This means I'll train on the dataset where `date_block_num < k` and predict for dataset where `date_block_num = k`, for `k in [31, 32, 33]`.\n",
    "\n",
    "I've prepared a train set which is basically the `sales_train.csv` grouped by month and without the first 20 months. Let's load that to start it out. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_block_num</th>\n",
       "      <th>item_id</th>\n",
       "      <th>shop_id</th>\n",
       "      <th>item_cnt_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.609124e+06</td>\n",
       "      <td>1.609124e+06</td>\n",
       "      <td>1.609124e+06</td>\n",
       "      <td>1.609124e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.466479e+01</td>\n",
       "      <td>1.068099e+04</td>\n",
       "      <td>3.280585e+01</td>\n",
       "      <td>2.022806e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.542322e+00</td>\n",
       "      <td>6.238883e+03</td>\n",
       "      <td>1.653701e+01</td>\n",
       "      <td>2.577964e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>5.045000e+03</td>\n",
       "      <td>2.100000e+01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.400000e+01</td>\n",
       "      <td>1.049700e+04</td>\n",
       "      <td>3.100000e+01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.300000e+01</td>\n",
       "      <td>1.606000e+04</td>\n",
       "      <td>4.700000e+01</td>\n",
       "      <td>2.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.300000e+01</td>\n",
       "      <td>2.216900e+04</td>\n",
       "      <td>5.900000e+01</td>\n",
       "      <td>2.000000e+01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       date_block_num       item_id       shop_id  item_cnt_month\n",
       "count    1.609124e+06  1.609124e+06  1.609124e+06    1.609124e+06\n",
       "mean     1.466479e+01  1.068099e+04  3.280585e+01    2.022806e+00\n",
       "std      9.542322e+00  6.238883e+03  1.653701e+01    2.577964e+00\n",
       "min      0.000000e+00  0.000000e+00  0.000000e+00    0.000000e+00\n",
       "25%      6.000000e+00  5.045000e+03  2.100000e+01    1.000000e+00\n",
       "50%      1.400000e+01  1.049700e+04  3.100000e+01    1.000000e+00\n",
       "75%      2.300000e+01  1.606000e+04  4.700000e+01    2.000000e+00\n",
       "max      3.300000e+01  2.216900e+04  5.900000e+01    2.000000e+01"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set = pd.read_parquet(os.path.join(PROCESSED_DATA_DIR, 'train-set.parquet'))\n",
    "train_set.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to use more of the dataset I'll use everything for CV and use the public LB score as the generalization score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(array([      0,       1,       2, ..., 1514426, 1514427, 1514428]),\n",
       "  array([1514429, 1514430, 1514431, ..., 1547912, 1547913, 1547914])),\n",
       " (array([      0,       1,       2, ..., 1547912, 1547913, 1547914]),\n",
       "  array([1547915, 1547916, 1547917, ..., 1577590, 1577591, 1577592])),\n",
       " (array([      0,       1,       2, ..., 1577590, 1577591, 1577592]),\n",
       "  array([1577593, 1577594, 1577595, ..., 1609121, 1609122, 1609123]))]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tscv.split(train_set['date_block_num'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With that we can use scikit learn to evaluate a regressor. Let's prepare our matrices and try a random forest just as an exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_splits = tscv.split(train_set['date_block_num'].values)\n",
    "X_train, y_train = train_set.drop(columns='item_cnt_month').values, train_set['item_cnt_month'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to remember to trim the outputs. For that I'll use a wrapper I wrote. Every estimator should be wrapped with it to have the output automatically clipped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from src.model import ClippedOutputRegressor\n",
    "\n",
    "reg = ClippedOutputRegressor(RandomForestRegressor(n_estimators=30, n_jobs=-1, verbose=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:  2.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([109.11260271, 110.04270244, 111.97539425]),\n",
       " 'score_time': array([0.15496159, 0.41551447, 0.51796556]),\n",
       " 'test_score': array([-0.83050309, -1.06552692, -1.12445434]),\n",
       " 'train_score': array([-0.30845238, -0.30658002, -0.3071537 ])}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_validate(reg, X=X_train, y=y_train,\n",
    "                        scoring=corrected_rmse_score, verbose=1, n_jobs=-1, \n",
    "                        cv=cv_splits, return_train_score=True)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.0068281133517571"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores['test_score'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can verify if our validation split is good by comparing with our generalization score. Since we're using the public LB, let's fit the model to the whole train set, create a submission and send it.\n",
    "\n",
    "The test set we generate predictions for is a subset of the full test set. The submission predictions will then be passed to a function that will generate the final dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "with zipfile.ZipFile(os.path.join(RAW_DATA_DIR, 'competitive-data-science-predict-future-sales.zip'), 'r') as datasets_file:\n",
    "    test_set = pd.read_csv(datasets_file.open('test.csv'))\n",
    "\n",
    "test_subset = pd.read_parquet(os.path.join(PROCESSED_DATA_DIR, 'test-subset.parquet'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:   42.3s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ClippedOutputRegressor(regressor=RandomForestRegressor(n_estimators=30,\n",
       "                                                       n_jobs=-1, verbose=1))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  30 out of  30 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "X_test = test_subset.values\n",
    "y_pred = reg.predict(X_test)\n",
    "test_subset['item_cnt_month'] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.submission import submission_from_subset\n",
    "\n",
    "submission = submission_from_subset(test_subset, test_set)\n",
    "submission.to_csv(os.path.join(TMP_DIR, 'rf-exercise-submission.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully submitted to Predict Future Sales"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2.46M/2.46M [01:32<00:00, 28.0kB/s]\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "kaggle c submit -f ${TMP_DIR}/rf-exercise-submission.csv -m 'testing CV score using a RF' competitive-data-science-predict-future-sales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The score on the public LB is 1.19355, which is a bit farther from our score than the holdout set was. Also, we can see the score equivalent to the holdout set on the scores map (it's the last one of the test set scores) and it's closer. Since we're not trying to build a model that is robust to temporal factors and we're just trying to predict a single month, we should probably focus more on the month that is closer or the same month from previous years.\n",
    "\n",
    "To validate this claim, let's try the CV only with months that are the same as the test set month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10, 22]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_months = [i for i in range(1, 34) if i % 12 == 34 % 12]\n",
    "test_months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_splits = tscv.split(train_set['date_block_num'].values, n=None, \n",
    "                       test_months=test_months)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:   46.7s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([27.06822729, 42.65053535]),\n",
       " 'score_time': array([0.41080236, 0.15328503]),\n",
       " 'test_score': array([-1.23908863, -1.20861024]),\n",
       " 'train_score': array([-0.31294194, -0.31232313])}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_validate(reg, X=X_train, y=y_train,\n",
    "                        scoring=corrected_rmse_score, verbose=1, n_jobs=-1, \n",
    "                        cv=cv_splits, return_train_score=True)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.2238494360890864"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(scores['test_score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's a lot closer. The only issue is that month 10 is too close to the beginning of the training set, so I'll probably want to use only month 22, otherwise our windows will be too tight. Either way, I won't change the validation now, but it's good to keep this in mind."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
