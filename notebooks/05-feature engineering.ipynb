{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Versions:\n",
      "  Python: 3.8.2 (default, Jul 16 2020, 14:00:26) \n",
      "[GCC 9.3.0]\n",
      "  pandas: 1.1.0\n",
      "  numpy: 1.19.1\n",
      "  seaborn: 0.10.1\n",
      "  sklearn: 0.23.2\n",
      "  altair: 4.1.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import scipy\n",
    "import altair as alt\n",
    "from altair import datum\n",
    "from tqdm.auto import tqdm, trange\n",
    "\n",
    "from src.model import tscv\n",
    "\n",
    "%run constants.py\n",
    "\n",
    "%matplotlib inline\n",
    "print(\"Versions:\")\n",
    "print(\"  Python: %s\" % sys.version)\n",
    "for module in [pd, np, sns, sklearn, alt]:\n",
    "    print(\"  %s: %s\" %(module.__name__, module.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "\n",
    "I think we have enough information to start with feature engineering now.\n",
    "\n",
    "The first step in my opinion is to define a validation pipeline, which is described in the next session.\n",
    "\n",
    "## Validation pipeline\n",
    "\n",
    "First of all, we need our metric, which sould be `sklearn.metrics.mean_squared_error(squared=False)`.\n",
    "\n",
    "Now, we need to decide how our training set should be split to validate a model. Since the problem is about forecasting, I chose to do a time-series split for this. This means I'll train on the dataset where `date_block_num < k` and predict for dataset where `date_block_num = k`, for `k in [31, 32, 33]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[Int64Index([      0,       1,       2,       3,       4,       5,       6,\n",
       "                    7,       8,       9,\n",
       "              ...\n",
       "              1506150, 1506151, 1506152, 1506153, 1506154, 1506155, 1506156,\n",
       "              1506157, 1506158, 1506159],\n",
       "             dtype='int64', length=1506160),\n",
       "  Int64Index([1506160, 1506161, 1506162, 1506163, 1506164, 1506165, 1506166,\n",
       "              1506167, 1506168, 1506169,\n",
       "              ...\n",
       "              1539636, 1539637, 1539638, 1539639, 1539640, 1539641, 1539642,\n",
       "              1539643, 1539644, 1539645],\n",
       "             dtype='int64', length=33486)],\n",
       " [Int64Index([      0,       1,       2,       3,       4,       5,       6,\n",
       "                    7,       8,       9,\n",
       "              ...\n",
       "              1539636, 1539637, 1539638, 1539639, 1539640, 1539641, 1539642,\n",
       "              1539643, 1539644, 1539645],\n",
       "             dtype='int64', length=1539646),\n",
       "  Int64Index([1539646, 1539647, 1539648, 1539649, 1539650, 1539651, 1539652,\n",
       "              1539653, 1539654, 1539655,\n",
       "              ...\n",
       "              1569314, 1569315, 1569316, 1569317, 1569318, 1569319, 1569320,\n",
       "              1569321, 1569322, 1569323],\n",
       "             dtype='int64', length=29678)],\n",
       " [Int64Index([      0,       1,       2,       3,       4,       5,       6,\n",
       "                    7,       8,       9,\n",
       "              ...\n",
       "              1569314, 1569315, 1569316, 1569317, 1569318, 1569319, 1569320,\n",
       "              1569321, 1569322, 1569323],\n",
       "             dtype='int64', length=1569324),\n",
       "  Int64Index([1569324, 1569325, 1569326, 1569327, 1569328, 1569329, 1569330,\n",
       "              1569331, 1569332, 1569333,\n",
       "              ...\n",
       "              1600845, 1600846, 1600847, 1600848, 1600849, 1600850, 1600851,\n",
       "              1600852, 1600853, 1600854],\n",
       "             dtype='int64', length=31531)]]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set = pd.read_parquet(os.path.join(PROCESSED_DATA_DIR, 'train-set-base.parquet'))\n",
    "tscv.split(train_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to use more of the dataset I'll use everything for CV and use the public LB score as the holdout set. This should be enough to make sure the model generalizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
